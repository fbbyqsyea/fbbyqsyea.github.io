<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-cn" lang="zh-cn">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.117.0">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Embedding And SentenceTransformers &middot; bing随遇而安</title>
  <meta name="description" content="" />

  
  <link type="text/css" rel="stylesheet" href="/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="/css/poole.css">
  <link type="text/css" rel="stylesheet" href="/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  
  
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">

  
  
</head>

  <body class="theme-base-0c ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="/"><h1>bing随遇而安</h1></a>
      <p class="lead">
       废柴都是间歇性的自虐 强者却是持续性的自律 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="/">首页</a> </li>
        <li><a href="//tags">标签</a> </li>
        
      </ul>
    </nav>

    <p>&copy; 2023. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>Embedding And SentenceTransformers</h1>
  <time datetime=2023-08-19T00:00:00Z class="post-date">Sat, Aug 19, 2023</time>
  <h2 id="什么是embedding">什么是Embedding?</h2>
<p>嵌入数据（Embedding Data）是一种将高维数据映射到低维空间的技术，通常应用于自然语言处理（NLP）和机器学习领域。在NLP中，词嵌入是一种常见的应用，它将单词映射到连续向量空间中，使得语义相近的词在向量空间中距离较近。</p>
<h2 id="什么是sentencetransformers">什么是SentenceTransformers？</h2>
<p>SentenceTransformers 是一个用于将句子、文本和图像生成嵌入的 Python 框架。您可以使用此框架来计算 100 多种语言的句子/文本嵌入。然后可以将这些嵌入与余弦相似度进行比较，以找到具有相似含义的句子。这对于语义文本相似、语义搜索或释义挖掘非常有用。</p>
<p>该框架基于PyTorch和Transformers，并提供了大量针对各种任务进行调整的预训练模型。此外，微调您自己的模型也很容易。</p>
<h2 id="如何使用sentencetransformers生成embedding">如何使用SentenceTransformers生成Embedding？</h2>
<p>下面我将以<code>BAAI/bge-large-zh</code>模型为例，演示如何使用SentenceTransformers来快速生成Embedding，和计算Embedding之间的相似性。</p>
<h4 id="安装sentencetransformers框架">安装<code>SentenceTransformers</code>框架</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># 安装SentenceTransformers框架</span>
</span></span><span style="display:flex;"><span>$ pip install -U sentence-transformers
</span></span></code></pre></div><h4 id="加载bge-large-zh模型">加载<code>bge-large-zh</code>模型</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 加载 bge-large-zh 模型</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> sentence_transformers <span style="color:#f92672">import</span> SentenceTransformer
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> SentenceTransformer(<span style="color:#e6db74">&#39;BAAI/bge-large-zh&#39;</span>)
</span></span></code></pre></div><h4 id="计算embedding">计算<code>Embedding</code></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 文本内容</span>
</span></span><span style="display:flex;"><span>sentence <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;数据线pd快充iphone14适配充电线短款双头Type-C公对公雷电3线适用苹果华为三星小米手机充电宝快充短线便携&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># encode</span>
</span></span><span style="display:flex;"><span>embedding <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode([sentence])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(embedding, len(embedding))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># [[-0.18654086 -0.4564763  -0.30071327 ... -0.43740666 -0.03736541</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#  -0.21082158]] 1</span>
</span></span></code></pre></div><h4 id="embedding相似性和距离"><code>Embedding</code>相似性和距离</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sentence_transformers <span style="color:#f92672">import</span> util
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 计算两个向量之间的相似性和距离</span>
</span></span><span style="display:flex;"><span>sentence_1 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;数据线pd快充iphone14适配充电线短款双头Type-C公对公雷电3线适用苹果华为三星小米手机充电宝快充短线便携&#34;</span>
</span></span><span style="display:flex;"><span>sentence_2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;小米&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>embedding_1 <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode([sentence_1])
</span></span><span style="display:flex;"><span>embedding_2 <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>encode([sentence_2])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 计算余弦相似性</span>
</span></span><span style="display:flex;"><span>cosine_similarity <span style="color:#f92672">=</span> util<span style="color:#f92672">.</span>pytorch_cos_sim(embedding_1, embedding_2)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 计算距离（1 - 余弦相似性）</span>
</span></span><span style="display:flex;"><span>distance <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> cosine_similarity<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(cosine_similarity, distance)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># tensor([[0.7151]]) 0.2849287986755371</span>
</span></span></code></pre></div>
</div>


    </main>

    
      
    
  </body>
</html>
